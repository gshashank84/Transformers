{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c83a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d8f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "class self_attention(keras.layers.Layer):\n",
    "    def __init__(self, units=512, dk=64, dv=64):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.dk = dk\n",
    "        self.dv = dv\n",
    "        self.scale_factor = 1/(self.dk**(1/2))\n",
    "        self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        #W_query\n",
    "        self.w_q = self.add_weight(shape=(self.units, self.dk),\n",
    "                                   initializer=\"random_normal\", \n",
    "                                   trainable=True)\n",
    "        #W_key\n",
    "        self.w_k = self.add_weight(shape=(self.units, self.dk),\n",
    "                                   initializer=\"random_normal\", \n",
    "                                   trainable=True)\n",
    "        #W_value\n",
    "        self.w_v = self.add_weight(shape=(self.units, self.dv),\n",
    "                                   initializer=\"random_normal\", \n",
    "                                   trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query = tf.matmul(inputs, self.w_q)\n",
    "        key = tf.matmul(inputs, self.w_k)\n",
    "        value = tf.matmul(inputs, self.w_v)\n",
    "        \n",
    "        # Q x K_T\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        # Summation: [q1k1+q1k2+q1k3+.., q2k1+q2k2+q2k3+.., ..]\n",
    "        score = tf.reduce_sum(score, axis=2, keepdims=True)\n",
    "        # Scaling the score with 1/sqrt(dk)\n",
    "        score = score*self.scale_factor\n",
    "        # Using softmax\n",
    "        normalized_score = self.softmax(score)\n",
    "        \n",
    "        z = normalized_score*value\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a33a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_head_attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_head=8, units=512):\n",
    "        super().__init__()\n",
    "        self.n_head = n_head\n",
    "        self.units = units # <- d_model\n",
    "        self.dk = self.units//self.n_head\n",
    "        self.dv = self.dk\n",
    "        self.attention = self_attention(units=self.units, dk=self.dk, dv=self.dv)\n",
    "        self.concat = tf.keras.layers.Concatenate(axis=-1)\n",
    "        self.W = self.add_weight(shape=(self.n_head*self.dv, self.units),\n",
    "                                   initializer=\"random_normal\", \n",
    "                                   trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        head_list = []\n",
    "        for _ in range(self.n_head):\n",
    "            head = self.attention(inputs)\n",
    "            head_list.append(head)\n",
    "            \n",
    "        concat_heads = self.concat(head_list)\n",
    "        z = tf.matmul(concat_heads, self.W)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc9786c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class add_normalize(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.normalize = tf.keras.layers.BatchNormalization()#tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Addition\n",
    "        x1 = self.add([inputs[0], inputs[1]])\n",
    "        # Normalization\n",
    "        x2 = self.normalize(x1)\n",
    "        \n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d169f26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=512, n_head=8):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.n_head = n_head\n",
    "        self.self_attention = multi_head_attention(self.n_head, self.units)\n",
    "        self.add_normalize = add_normalize()\n",
    "        self.dense = tf.keras.layers.Dense(self.units, \n",
    "                                           activation='relu',\n",
    "                                           kernel_initializer='glorot_uniform')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Self-Attention\n",
    "        x1 = self.self_attention(inputs)\n",
    "        \n",
    "        # Add & Normalize\n",
    "        x2 = self.add_normalize([inputs, x1])\n",
    "        \n",
    "        # Feed Forward\n",
    "        x3 = self.dense(x2)\n",
    "        \n",
    "        # Add & Normalize\n",
    "        x4 = self.add_normalize([x2, x3])\n",
    "        \n",
    "        return x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba64118",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bert_base(tf.keras.layers.Layer):\n",
    "    def __init__(self, L=12, H=768, A=12):\n",
    "        super().__init__()\n",
    "        # L -> Number of transformer blocks (encoders)\n",
    "        # H -> Hidden vector size\n",
    "        # A -> Number of Attention Heads\n",
    "        self.L = L\n",
    "        self.H = H\n",
    "        self.A = A\n",
    "        \n",
    "        # transformer block (encoder)\n",
    "        self.encoder_block = encoder(units=self.H, n_head=self.A)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for _ in range(self.L):\n",
    "            x = self.encoder_block(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9c694fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(10,768,))\n",
    "outputs = bert_base(L=12, H=768, A=12)(inputs)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2985e0ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10, 768)]         0         \n",
      "_________________________________________________________________\n",
      "bert_base (bert_base)        (None, 10, 768)           1330944   \n",
      "=================================================================\n",
      "Total params: 1,330,944\n",
      "Trainable params: 1,329,408\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0a90e44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"Bert_Base.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e13dd8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder_decoder_attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=512, dk=64, dv=64):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.dk = dk\n",
    "        self.dv = dv\n",
    "        self.scale_factor = 1/(self.dk**(1/2))\n",
    "        self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        encoder_out_shape, decoder_in_shape = input_shape[0], input_shape[1]\n",
    "        \n",
    "        # W_query\n",
    "        self.w_q = self.add_weight(shape=(encoder_out_shape[2], self.dk),\n",
    "                                   initializer=\"random_normal\", \n",
    "                                   trainable=True)\n",
    "        # W_key\n",
    "        self.w_k = self.add_weight(shape=(encoder_out_shape[2], self.dk),\n",
    "                                   initializer=\"random_normal\", \n",
    "                                   trainable=True)\n",
    "        # W_value\n",
    "        self.w_v = self.add_weight(shape=(decoder_in_shape[2], self.dv),\n",
    "                                   initializer=\"random_normal\", \n",
    "                                   trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoder_output, decoder_input = inputs[0], inputs[1]\n",
    "        \n",
    "        query = tf.matmul(encoder_output, self.w_q)\n",
    "        key = tf.matmul(encoder_output, self.w_k)\n",
    "        value = tf.matmul(decoder_input, self.w_v)\n",
    "        \n",
    "        # Q x K_T\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        # Summation: [q1k1+q1k2+q1k3+.., q2k1+q2k2+q2k3+.., ..]\n",
    "        score = tf.reduce_sum(score, axis=2, keepdims=True)\n",
    "        # Scaling the score with 1/sqrt(dk)\n",
    "        score = score*self.scale_factor\n",
    "        # Using softmax\n",
    "        normalized_score = self.softmax(score)\n",
    "        \n",
    "        z = normalized_score*value\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1312c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_e_d_attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_head=8, units=512):\n",
    "        super().__init__()\n",
    "        self.n_head = n_head\n",
    "        self.units = units # <- d_model\n",
    "        self.dk = self.units//self.n_head\n",
    "        self.dv = self.dk\n",
    "        self.attention = encoder_decoder_attention(units=self.units, dk=self.dk, dv=self.dv)\n",
    "        self.concat = tf.keras.layers.Concatenate(axis=-1)\n",
    "        self.W = self.add_weight(shape=(self.n_head*self.dv, self.units),\n",
    "                                   initializer=\"random_normal\", \n",
    "                                   trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        head_list = []\n",
    "        for _ in range(self.n_head):\n",
    "            head = self.attention(inputs)\n",
    "            head_list.append(head)\n",
    "            \n",
    "        concat_heads = self.concat(head_list)\n",
    "        z = tf.matmul(concat_heads, self.W)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c964ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=512, n_head=8):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.n_head = n_head\n",
    "        self.dk = self.units//self.n_head\n",
    "        self.self_attention = multi_head_attention(self.n_head, self.units)\n",
    "        self.add_normalize = add_normalize()\n",
    "        self.encoder_decoder_attention = multi_e_d_attention(n_head=self.n_head,\n",
    "                                                             units=self.units)\n",
    "        self.dense = tf.keras.layers.Dense(self.units, \n",
    "                                           activation='relu',\n",
    "                                           kernel_initializer='glorot_uniform')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Encoder's output & Decoder's input\n",
    "        encoder_output, decoder_input = inputs[0], inputs[1]\n",
    "        \n",
    "        # Self-Attention\n",
    "        x1 = self.self_attention(decoder_input)\n",
    "        \n",
    "        # Add & Normalize\n",
    "        x2 = self.add_normalize([decoder_input, x1])\n",
    "        \n",
    "        # Encoder-Decoder Attenion\n",
    "        x3 = self.encoder_decoder_attention([encoder_output, x2])\n",
    "        \n",
    "        # Add & Normalize\n",
    "        x4 = self.add_normalize([x2, x3])\n",
    "        \n",
    "        # Feed Forward\n",
    "        x5 = self.dense(x4)\n",
    "        \n",
    "        # Add & Normalize\n",
    "        x6 = self.add_normalize([x4, x5])\n",
    "        \n",
    "        return x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6432b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder_Nx(tf.keras.layers.Layer):\n",
    "    def __init__(self, N=6, units=512, n_head=8):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.units = units\n",
    "        self.n_head = n_head\n",
    "        self.encoder_block = encoder(units=self.units, n_head=self.n_head)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for _ in range(self.N):\n",
    "            x = self.encoder_block(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fad6fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder_Nx(tf.keras.layers.Layer):\n",
    "    def __init__(self, N=6, units=512, n_head=8):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.units = units\n",
    "        self.n_head = n_head\n",
    "        self.decoder_block = decoder(units=self.units, n_head=self.n_head)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Encoder's output & Decoder's input\n",
    "        encoder_output, x = inputs[0], inputs[1]\n",
    "        \n",
    "        for _ in range(self.N):\n",
    "            x = self.decoder_block([encoder_output, x])\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bef8a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformer(tf.keras.layers.Layer):\n",
    "    def __init__(self, N=6, units=512, n_head=8, vocab_size=1024):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.units = units\n",
    "        self.n_head = n_head\n",
    "        self.vocab_size = vocab_size\n",
    "        self.encoder_Nx = encoder_Nx(N=self.N, units=self.units, n_head=self.n_head)\n",
    "        self.decoder_Nx = decoder_Nx(N=self.N, units=self.units, n_head=self.n_head)\n",
    "        self.dense = tf.keras.layers.Dense(self.vocab_size, \n",
    "                                           activation=None,\n",
    "                                           kernel_initializer='glorot_uniform')\n",
    "        self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Encoder's input, Decoder's input\n",
    "        encoder_input, decoder_input = inputs[0], inputs[1]\n",
    "        \n",
    "        x1 = self.encoder_Nx(encoder_input)\n",
    "        x2 = self.decoder_Nx([x1, decoder_input])\n",
    "        x3 = self.dense(x2)\n",
    "        x4 = self.softmax(x3)\n",
    "        \n",
    "        return x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "713421f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encoder_inputs = keras.Input(shape=(10,512,), name='encoder_inputs')\n",
    "decoder_inputs = keras.Input(shape=(10,512,), name='decoder_inputs')\n",
    "outputs= transformer(N=6,units=512,n_head=8,vocab_size=1024)([encoder_inputs,decoder_inputs])\n",
    "\n",
    "model = keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acb4cbb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, 10, 512)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     [(None, 10, 512)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "transformer (transformer)       (None, 10, 1024)     2136064     encoder_inputs[0][0]             \n",
      "                                                                 decoder_inputs[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 2,136,064\n",
      "Trainable params: 2,134,016\n",
      "Non-trainable params: 2,048\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da822fb3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"Transformer.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2221abe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
